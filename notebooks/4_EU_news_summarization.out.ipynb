{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Article summarization code"
   ],
   "id": "fa2919da-526f-487a-aeae-3301adea5d79"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [],
   "id": "cell-1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import prompt_templates_summarization as pts\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain_google_genai import (\n",
    "    ChatGoogleGenerativeAI,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory\n",
    ")\n",
    "from json.decoder import JSONDecodeError\n",
    "from google.generativeai.types import BlockedPromptException\n",
    "from google.generativeai.types.generation_types import StopCandidateException"
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"Italy\"\n",
    "path2SP = \".../EU-S Data/\""
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading API key"
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GoogleAI_key = os.getenv(\"googleAI_API_key\")\n",
    "os.environ['GOOGLE_API_KEY'] = GoogleAI_key"
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showEverything(df):\n",
    "    with pd.option_context('display.max_rows', None,\n",
    "                        'display.max_columns', None,\n",
    "                        'display.width', 1000,\n",
    "                        'display.precision', 3,\n",
    "                        'display.colheader_justify', 'left'):\n",
    "        display(df)"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_data      = pd.read_parquet(f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-classification-1/0_compiled/{country}_classified.parquet.gzip\")\n",
    "location_variable = f\"location_{country}\"\n",
    "if country == \"Czechia\":\n",
    "    location_variable = f\"location_Czech\"\n",
    "subset_data       = (\n",
    "    country_data.copy()\n",
    "    .loc[(country_data[location_variable] == True) & (country_data[\"topic_related\"].str.contains(\"Related|Justice|Governance\"))]\n",
    ")\n",
    "subset_data.shape"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pillar_columns = subset_data.filter(like='pillar_')\n",
    "pillar_sum = pillar_columns.sum(axis=0)\n",
    "pillar_sum"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining chain"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "}"
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"\n",
    "        Parse the output of an LLM call to a valid JSON format.\n",
    "        \"\"\"\n",
    "        return json.loads(text.replace('```json', '').replace('```', ''), strict=False)"
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(headline, summary, body, pillar):\n",
    "    \"\"\"\n",
    "    This function takes a headline, a summary, and the content of a news article and it sends a call to Google's Gemini\n",
    "    to summarize a article and provide an impact score focusing on a specific pillar of the Rule of Law.\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = str(pillar)\n",
    "\n",
    "    # Setting up the Prompt Template\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "                    (\"system\", pts.context),\n",
    "                    (\"human\", pts.instructions)\n",
    "                ])\n",
    "\n",
    "    # Defining our chain\n",
    "    chain_gemini = chat_prompt | ChatGoogleGenerativeAI(model = \"gemini-pro\",\n",
    "                                                        temperature = 0.1, \n",
    "                                                        safety_settings = safety_settings,\n",
    "                                                        convert_system_message_to_human = True) | JSONOutputParser()\n",
    "    \n",
    "    try: \n",
    "        llm_response = chain_gemini.invoke({\n",
    "            \"headline\"       : headline,\n",
    "            \"summary\"        : summary,\n",
    "            \"body\"           : body,\n",
    "            \"pillar_name\"    : pts.pillar_names[idx],\n",
    "            \"pillar_bullets\" : pts.pillar_bullets[idx]\n",
    "        })\n",
    "        status = True\n",
    "        time.sleep(3)   # We need to slow down the calls. given that the Gemini API has a limit of 60 calls per second\n",
    "\n",
    "    # The API can still block some of our prompts due to undefined reasons. Sadly, we can't do anything about it, so we\n",
    "    # predefine the outcome    \n",
    "    except (BlockedPromptException, StopCandidateException):\n",
    "        print(\"Prompt BLOCKED\")\n",
    "        status = False\n",
    "    \n",
    "    except JSONDecodeError:\n",
    "        print(\"Decode error... trying again...\")\n",
    "        try: \n",
    "            llm_response = chain_gemini.invoke({\n",
    "                \"headline\"       : headline,\n",
    "                \"summary\"        : summary,\n",
    "                \"body\"           : body,\n",
    "                \"pillar_name\"    : pts.pillar_names[idx],\n",
    "                \"pillar_bullets\" : pts.pillar_bullets[idx]\n",
    "            })\n",
    "            status = True\n",
    "            time.sleep(3)\n",
    "\n",
    "        except JSONDecodeError:\n",
    "            print(\"Failed. Skipping article.\")\n",
    "            status = False\n",
    "\n",
    "    # We use the STATUS variable to throw an outcome to our call depending if our prompt was blocked or not\n",
    "    if status == True:\n",
    "        outcome = [llm_response[\"summary\"], llm_response[\"impact_score\"]]\n",
    "\n",
    "    else:\n",
    "        outcome = \"Skipped article\"\n",
    "\n",
    "    return outcome"
   ],
   "id": "cell-13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending calls in sets and batches"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-summarization/{country}\")\n",
    "    print(\"Directory created\")\n",
    "except FileExistsError:\n",
    "    print(\"Directory already exists\")\n",
    "try:\n",
    "    for p in range(1,9):\n",
    "        os.mkdir(f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-summarization/{country}/pillar_{p}\")\n",
    "    print(\"Sub-directories created\")\n",
    "except FileExistsError:\n",
    "    print(\"Sub-directories already exists\")"
   ],
   "id": "cell-15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(1,9):\n",
    "\n",
    "    print(\"=========================\")\n",
    "    print(f\"Starting with PILLAR {p}\")\n",
    "    print(\"=========================\")\n",
    "\n",
    "    pillar_subset = (\n",
    "        subset_data.copy()\n",
    "        .loc[subset_data[f\"pillar_{p}\"] == True]\n",
    "    )\n",
    "    nsets = math.ceil(len(pillar_subset)/1000)\n",
    "\n",
    "    for set in range(1, nsets+!):\n",
    "        print(\"==============================================\")\n",
    "        print(f\"Starting with SET {set} out of {nsets} set(s)\")\n",
    "        print(\"==============================================\")\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for batch_number in range(1,11):\n",
    "            starting_row = ((set-1)*1000)+((batch_number-1)*100)\n",
    "            end_row      = starting_row+100\n",
    "            batch_subset = pillar_subset.copy().iloc[starting_row:end_row]\n",
    "\n",
    "            if len(batch_subset) > 0 :\n",
    "                print(\"============================================================================\")\n",
    "                print(f\"Sending batch number: {batch_number}, start: {starting_row}, end: {end_row}\")\n",
    "                print(\"============================================================================\")\n",
    "\n",
    "                batch_subset[[\"summary\", \"impact_score\"]] = batch_subset.apply(lambda row: pd.Series(summarize_article(\n",
    "                    row[\"title_trans\"], \n",
    "                    row[\"description_trans\"], \n",
    "                    row[\"content_trans\"], \n",
    "                    p\n",
    "                )), axis = 1)\n",
    "                results.append(batch_subset)\n",
    "\n",
    "        # Collapsing and saving data\n",
    "        collapsed_data = pd.concat(results).drop_duplicates(subset=\"id\")\n",
    "        collapsed_data.loc[collapsed_data[\"impact_score\"] == \"N/A\", \"impact_score\"] = 0\n",
    "        collapsed_data[\"impact_score\"] = collapsed_data[\"impact_score\"].fillna(0).astype(int)\n",
    "        collapsed_data.to_parquet(f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-summarization/{country}/pillar_{p}/{country}_pillar_{p}_set_{set}.parquet.gzip\", compression=\"gzip\")\n",
    "        time.sleep(5)"
   ],
   "id": "cell-16"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
