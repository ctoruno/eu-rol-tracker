{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification code"
   ],
   "id": "9ad35479-6bee-4ffa-9f2d-f46a538939ed"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [],
   "id": "cell-1"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import prompt_templates_classification as ptc\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain_google_genai import (\n",
    "    ChatGoogleGenerativeAI,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory\n",
    ")\n",
    "from json.decoder import JSONDecodeError\n",
    "from google.generativeai.types import BlockedPromptException\n",
    "from google.generativeai.types.generation_types import StopCandidateException"
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"Italy\"\n",
    "path2SP = \".../EU-S Data/\""
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading API key"
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GoogleAI_key = os.getenv(\"googleAI_API_key\")\n",
    "os.environ['GOOGLE_API_KEY'] = GoogleAI_key"
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_data = pd.read_parquet(f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-extraction-1/ready4class/{country}_translated.parquet.gzip\")\n",
    "country_data.head(5)"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Chain"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "}"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"\n",
    "        Parse the output of an LLM call to a valid JSON format.\n",
    "        \"\"\"\n",
    "        return json.loads(text.replace('```json', '').replace('```', ''), strict=False)"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_article(headline, summary, body, id = None, stage_1 = True, relation = None):\n",
    "    \"\"\"\n",
    "    This function takes a headline, a summary, and the content of a news article and it sends a call to Google's Gemini\n",
    "    to classify the article. There are two different classifications: Stage 1 and Stage 2. If stage_1 is set to TRUE, then\n",
    "    the call to the model will try to answer the following question: Is this news article related or unrelated to the Rule of Law?\n",
    "    If stage_1 is set to FALSE, then the call to the model will try to rate how closely related is the news article to each\n",
    "    one of the eight pillars of the Rule of Law.\n",
    "    \"\"\"\n",
    "    # print(id)\n",
    "\n",
    "    # Defining the prompt according to which stage are we calling the function for\n",
    "    if stage_1 == True:\n",
    "        system_prompt = ptc.context_stage_1\n",
    "        human_prompt  = ptc.instructions_stage_1\n",
    "    else:\n",
    "        system_prompt = ptc.context_stage_2\n",
    "        human_prompt  = ptc.instructions_stage_2\n",
    "\n",
    "    # Setting up the Prompt Template\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "                    # (\"system\", system_prompt),\n",
    "                    (\"human\", human_prompt),\n",
    "                ])\n",
    "\n",
    "    # Defining our chain\n",
    "    chain_gemini = chat_prompt | ChatGoogleGenerativeAI(model = \"gemini-pro\",\n",
    "                                                        temperature     = 0.1, \n",
    "                                                        safety_settings = safety_settings,\n",
    "                                                        convert_system_message_to_human = True) | JSONOutputParser()\n",
    "    \n",
    "    # For Stage 2, we don't want to pass articles that were already classified as \"UNRELATED\", so we pre-defined the outcome\n",
    "    if stage_1 == False and all(keyword not in relation for keyword in [\"Related\", \"Justice\", \"Governance\"]):\n",
    "        outcome = \"Unrelated\"\n",
    "\n",
    "    else:\n",
    "        try: \n",
    "            llm_response = chain_gemini.invoke({\n",
    "                \"headline\": headline,\n",
    "                \"summary\" : summary,\n",
    "                \"body\"    : body,\n",
    "            })\n",
    "            status = True\n",
    "            time.sleep(1)   # We need to slow down the calls. given that the Gemini API has a limit of 60 calls per second\n",
    "\n",
    "        # The API can still block some of our prompts due to undefined reasons. Sadly, we can't do anything about it, so we\n",
    "        # predefine the outcome    \n",
    "        except (BlockedPromptException, StopCandidateException):\n",
    "            print(\"Prompt BLOCKED\")\n",
    "            status = False\n",
    "        \n",
    "        except JSONDecodeError:\n",
    "            print(\"Decode error... trying again...\")\n",
    "            try: \n",
    "                llm_response = chain_gemini.invoke({\n",
    "                    \"headline\": headline,\n",
    "                    \"summary\" : summary,\n",
    "                    \"body\"    : body,\n",
    "                })\n",
    "                status = True\n",
    "                time.sleep(1)\n",
    "            except JSONDecodeError:\n",
    "                print(\"Failed. Skipping article.\")\n",
    "                status = False\n",
    "\n",
    "        # We use the STATUS variable to throw an outcome to our call depending if our prompt was blocked or not and\n",
    "        # on the stage we are calling the function for\n",
    "        if status == True:\n",
    "            if stage_1 == True:\n",
    "                if \"Governance\" in llm_response[\"rol_related\"]:\n",
    "                    llm_response[\"rol_related\"] == \"Related\"\n",
    "                if \"Justice\" in llm_response[\"rol_related\"]:\n",
    "                    llm_response[\"rol_related\"] == \"Related\"\n",
    "                outcome = [llm_response[\"rol_related\"], llm_response[\"country\"]]\n",
    "\n",
    "            else:\n",
    "                outcome = json.dumps(llm_response[\"pillars_relation\"])\n",
    "        else:\n",
    "            outcome = \"Skipped article\"\n",
    "\n",
    "    return outcome"
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_data.shape"
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending calls in sets and batches"
   ],
   "id": "cell-13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-classification-1/{country}\")\n",
    "    print(\"Directory created\")\n",
    "except FileExistsError:\n",
    "    print(\"Directory already exists\")"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsets = math.ceil(len(country_data)/1000)\n",
    "for set in range(1, nsets+1):\n",
    "    \n",
    "    print(\"=======================================\")\n",
    "    print(f\"Starting with SET {set} out of {nsets}\")\n",
    "    print(\"=======================================\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for batch_number in range(1,11):\n",
    "\n",
    "        # Subsetting data\n",
    "        starting_row = ((set-1)*1000)+((batch_number-1)*100)\n",
    "        end_row      = starting_row+100\n",
    "        batch_subset = country_data.copy().iloc[starting_row:end_row]\n",
    "\n",
    "        if len(batch_subset) > 0 :\n",
    "            print(\"============================================================================\")\n",
    "            print(f\"Sending batch number: {batch_number}, start: {starting_row}, end: {end_row}\")\n",
    "            print(\"============================================================================\")\n",
    "            \n",
    "            # Applying classifiers\n",
    "            print(\"====== STAGE 1 =====\")\n",
    "            batch_subset[[\"topic_related\", \"location_events\"]] = batch_subset.apply(lambda row: pd.Series(classify_article(\n",
    "                row[\"title_trans\"], \n",
    "                row[\"description_trans\"], \n",
    "                row[\"content_trans\"], \n",
    "                row[\"id\"],\n",
    "                stage_1 = True\n",
    "            )), axis = 1)\n",
    "\n",
    "            print(\"====== STAGE 2 =====\")\n",
    "            batch_subset[\"pillars_score\"] = batch_subset.apply(lambda row: classify_article(\n",
    "                row[\"title_trans\"], \n",
    "                row[\"description_trans\"], \n",
    "                row[\"content_trans\"], \n",
    "                row[\"id\"],\n",
    "                relation = row[\"topic_related\"],\n",
    "                stage_1  = False\n",
    "            ), axis = 1)\n",
    "\n",
    "            results.append(batch_subset)\n",
    "\n",
    "    # Collapsing and saving data\n",
    "    collapsed_data = pd.concat(results).drop_duplicates(subset=\"id\")\n",
    "    collapsed_data.to_parquet(f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-classification-1/{country}/{country}_set_{set}.parquet.gzip\", compression=\"gzip\")\n",
    "    time.sleep(5)"
   ],
   "id": "cell-15"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling sets"
   ],
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data_list = [\n",
    "    pd.read_parquet(f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-classification-1/{country}/{file}\") \n",
    "    for file in os.listdir(f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-classification-1/{country}\")\n",
    "]\n",
    "classified_data = pd.concat(classified_data_list)"
   ],
   "id": "cell-17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting pillar scores to binary"
   ],
   "id": "cell-18"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_score(string, pillar, t = 7):\n",
    "    \"\"\"\n",
    "    This function extracts scores from a string and returns a binary value that is equal to 1 if the score is higher/equal\n",
    "    than a specific threshold, and it returns zero if otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        scores_dicts = ast.literal_eval(string)\n",
    "        ratings = [v for x in scores_dicts for _,v in x.items()]\n",
    "        keys    = [k for x in scores_dicts for k,_ in x.items()]\n",
    "        pattern = str(pillar) + \". \"\n",
    "        idx     = next((index for index, element in enumerate(keys) if pattern in element), None)\n",
    "\n",
    "        if idx is not None:\n",
    "            score = ratings[idx]\n",
    "        else:\n",
    "            score = 0\n",
    "            \n",
    "        if score >= t:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    except ValueError:\n",
    "        if string == \"Unrelated\":\n",
    "            return 0\n",
    "    \n",
    "    except SyntaxError:\n",
    "        if string == \"Skipped article\":\n",
    "            return 0"
   ],
   "id": "cell-19"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 9):\n",
    "    var_name     = \"pillar_\" + str(i)\n",
    "    classified_data[var_name] = classified_data[\"pillars_score\"].apply(lambda x: extract_score(x, i))"
   ],
   "id": "cell-20"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning location of events and topic relation"
   ],
   "id": "cell-21"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc2bin(location, country):\n",
    "    if pd.isna(location):\n",
    "        return False\n",
    "    elif country in location:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "id": "cell-22"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_member_states = [\n",
    "    \"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech\", \"Denmark\", \"Estonia\", \"Finland\", \"France\",\n",
    "    \"Germany\", \"Greece\", \"Hungary\", \"Ireland\", \"Italy\", \"Latvia\", \"Lithuania\", \"Luxembourg\", \"Malta\", \"Netherlands\",\n",
    "    \"Poland\", \"Portugal\", \"Romania\", \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\", \"Euro\"\n",
    "]\n",
    "for member in eu_member_states:\n",
    "    var_name = f\"location_{member}\"\n",
    "    classified_data[var_name] = classified_data[\"location_events\"].apply(lambda x: loc2bin(x, member))"
   ],
   "id": "cell-23"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ],
   "id": "cell-24"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data.to_parquet(f\"{path2SP}/EU-S Data/Automated Qualitative Checks/Data/data-classification-1/0_compiled/{country}_classified.parquet.gzip\", compression=\"gzip\")"
   ],
   "id": "cell-25"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
