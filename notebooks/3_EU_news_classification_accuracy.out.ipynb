{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification Performance Assessment"
   ],
   "id": "2852a442-30d6-478d-b16e-43eeaad24cd9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [],
   "id": "cell-1"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import getpass"
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_data = pd.read_parquet(f\"/Users/{getpass.getuser()}/OneDrive - World Justice Project/EU Subnational/EU-S Data/Automated Qualitative Checks/Data/GPT-vs-Gemini-data.parquet.gzip\")\n",
    "EU_team = pd.read_parquet(f\"/Users/{getpass.getuser()}/OneDrive - World Justice Project/EU Subnational/EU-S Data/Automated Qualitative Checks/Data/human_labelling.parquet.gzip\")\n",
    "EU_team = EU_team[EU_team['bucket'] != \"hortiz\"]\n",
    "horacio = pd.read_parquet(f\"/Users/{getpass.getuser()}/OneDrive - World Justice Project/EU Subnational/EU-S Data/Automated Qualitative Checks/Data/hortiz.parquet.gzip\")"
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics Function"
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(df, predicted_column, truth_column):\n",
    "    true_pos   = len(df[(df[predicted_column] == 1) & (df[truth_column] == 1)])\n",
    "    true_neg   = len(df[(df[predicted_column] == 0) & (df[truth_column] == 0)])\n",
    "    false_neg  = len(df[(df[predicted_column] == 0) & (df[truth_column] == 1)])\n",
    "    false_pos  = len(df[(df[predicted_column] == 1) & (df[truth_column] == 0)])\n",
    "\n",
    "    accuracy  = (true_pos + true_neg) / (true_neg + true_pos + false_neg + false_pos) \n",
    "    precision = ((true_pos) / (true_pos + false_pos)) if (true_pos + false_pos) > 0 else 0\n",
    "    recall    = ((true_pos) / (true_pos + false_neg)) if (true_pos + false_neg) > 0 else 0\n",
    "    f1        = (2*((precision*recall) / (precision+recall))) if (recall != 0) else 0\n",
    "    tpr       = ((true_pos)/(true_pos + false_neg)) if (true_pos + false_neg) > 0 else 0\n",
    "    fpr       = ((false_pos)/(false_pos + true_neg)) if (false_pos + true_neg) > 0 else 0 \n",
    "    c_matrix  = np.array(\n",
    "        [[true_neg, false_pos],[false_neg, true_pos]]\n",
    "    )\n",
    "    mcc       = ((true_pos*true_neg) - (false_pos*false_neg)) / math.sqrt((true_pos+false_pos)*(true_pos+false_neg)*(true_neg+false_pos)*(true_neg+false_neg)) if (\n",
    "        math.sqrt((true_pos+false_pos)*(true_pos+false_neg)*(true_neg+false_pos)*(true_neg+false_neg))) > 0 else 0\n",
    "\n",
    "    summary = {\n",
    "        'accuracy' : accuracy,\n",
    "        'precision' : precision,\n",
    "        'recall' : recall,\n",
    "        'f1' : f1,\n",
    "        'mcc' : mcc,\n",
    "        'tpr' : tpr,\n",
    "        'fpr' : fpr,\n",
    "        'confusion_matrix' : c_matrix,\n",
    "        'true_pos' : true_pos,\n",
    "        'true_neg' : true_neg,\n",
    "        'false_pos' : false_pos,\n",
    "        'false_neg' : false_neg\n",
    "    }\n",
    "\n",
    "    return summary"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling AI Data"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_data['horacio_rol'] = (\n",
    "    AI_data[[\n",
    "        'horacio_pillar_1', 'horacio_pillar_2', 'horacio_pillar_3', 'horacio_pillar_4',\n",
    "        'horacio_pillar_5', 'horacio_pillar_6', 'horacio_pillar_7', 'horacio_pillar_8'\n",
    "    ]].eq(1).any(axis=1)\n",
    ").astype(int)\n",
    "AI_data['GPT_ROL'] = (AI_data['factor(s)'] != \"Not related to Rule of Law\").astype(int)\n",
    "AI_data['Gemini_ROL'] = (AI_data['gemini_stage_1'] != \"Unrelated\").astype(int)"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling Human Data"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "horacio['horacio_ROL'] = np.where((horacio['factor(s)'] != \"Not related to Rule of Law\"),1,0)\n",
    "EU_team['model_ROL']   = np.where((EU_team['factor(s)'] != \"Not related to Rule of Law\"),1,0)\n",
    "\n",
    "for df in [horacio, EU_team]:\n",
    "    df['factor(s)'] = df['factor(s)'].astype(str)\n",
    "\n",
    "pillars = [i for i in range(1,9)]\n",
    "for pillar in pillars:\n",
    "    horacio[f'horacio_pillar_{pillar}'] = horacio['factor(s)'].apply(lambda x: int(bool(re.search(f'{pillar}:', str(x)))))\n",
    "    EU_team[f'model_pillar_{pillar}'] = EU_team['factor(s)'].apply(lambda x: int(bool(re.search(f'{pillar}:', str(x)))))\n",
    "\n",
    "horacio = horacio.drop(columns = ['link', 'factor(s)', 'sentiment', 'is_eu_related','related_country', 'comments'])\n",
    "EU_team = EU_team.drop(columns = ['link', 'factor(s)', 'sentiment', 'is_eu_related', 'related_country', 'comments'])"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "\n",
    "for model in EU_team['bucket'].unique():\n",
    "    subset = EU_team.loc[EU_team['bucket'] == model]\n",
    "    human_vs_horacio = pd.merge(subset, horacio, on = \"article_id\", how = \"inner\")\n",
    "    dataframes[model] = human_vs_horacio\n",
    "    n_articles = len(human_vs_horacio)"
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage One Metrics"
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPT metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'mcc': 1.0, 'tpr': 1.0, 'fpr': 0.0, 'confusion_matrix': array([[136,   0],\n",
      "       [  0,  67]]), 'true_pos': 67, 'true_neg': 136, 'false_pos': 0, 'false_neg': 0}\n",
      "Gemini metrics:  {'accuracy': 0.7980295566502463, 'precision': 0.782608695652174, 'recall': 0.5373134328358209, 'f1': 0.6371681415929203, 'mcc': 0.5209474243346167, 'tpr': 0.5373134328358209, 'fpr': 0.07352941176470588, 'confusion_matrix': array([[126,  10],\n",
      "       [ 31,  36]]), 'true_pos': 36, 'true_neg': 126, 'false_pos': 10, 'false_neg': 31}"
     ]
    }
   ],
   "source": [
    "gpt_metrics = calculate_performance(AI_data, 'GPT_ROL', 'horacio_rol')\n",
    "print('GPT metrics:', gpt_metrics)\n",
    "gemini_metrics = calculate_performance(AI_data, 'Gemini_ROL', 'horacio_rol')\n",
    "print('Gemini metrics: ', gemini_metrics)"
   ],
   "id": "cell-13"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_performance = pd.DataFrame()\n",
    "\n",
    "for classifier in dataframes:\n",
    "    metrics = calculate_performance(dataframes[classifier], 'model_ROL', 'horacio_ROL')\n",
    "    new_row = {\n",
    "        'classifier': classifier, \n",
    "        'accuracy': metrics['accuracy'], \n",
    "        'precision': metrics['precision'], \n",
    "        'recall': metrics['recall'], \n",
    "        'f1': metrics['f1'], \n",
    "        'mcc': metrics['mcc'],\n",
    "        'tpr' : metrics['tpr'],\n",
    "        'fpr' : metrics['fpr'],\n",
    "        'confusion_matrix': metrics['confusion_matrix'],  # Store the confusion matrix if needed\n",
    "        'true_pos' : metrics['true_pos'],\n",
    "        'true_neg' : metrics['true_neg'],\n",
    "        'false_pos' : metrics['false_pos'],\n",
    "        'false_neg' : metrics['false_neg']\n",
    "    }\n",
    "    new_row = pd.DataFrame([new_row])\n",
    "    classification_performance = pd.concat([classification_performance, new_row], ignore_index = True)"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_one_summary = []\n",
    "gpt_stage_one = {\n",
    "    'tpr' : gpt_metrics[\"tpr\"],\n",
    "    \"fpr\" : gpt_metrics[\"fpr\"],\n",
    "    'confusion_matrix' : gpt_metrics[\"confusion_matrix\"],\n",
    "    'classifier' : 'GPT'\n",
    "}\n",
    "gem_stage_one = {\n",
    "    'tpr' : gemini_metrics[\"tpr\"],\n",
    "    \"fpr\" : gemini_metrics[\"fpr\"],\n",
    "    'confusion_matrix' : gemini_metrics[\"confusion_matrix\"],\n",
    "    'classifier' : 'Gemini'\n",
    "}\n",
    "\n",
    "top = classification_performance.loc[\n",
    "    (classification_performance['tpr'] > 0.8)\n",
    "]\n",
    "top_eu = {\n",
    "    'tpr' : top['tpr'].mean(),\n",
    "    'fpr' : top['fpr'].mean(),\n",
    "    'confusion_matrix' : top['confusion_matrix'].sum(),\n",
    "    'classifier' : 'Top Human Classifiers'\n",
    "}\n",
    "all_of_eu = {\n",
    "    'tpr' : classification_performance['tpr'].mean(),\n",
    "    'fpr' : classification_performance['fpr'].mean(),\n",
    "    'confusion_matrix' : classification_performance['confusion_matrix'].sum(),\n",
    "    'classifier' : 'Human Classifiers'\n",
    "}\n",
    "\n",
    "for i in [gpt_stage_one, gem_stage_one, top_eu, all_of_eu]:\n",
    "    stage_one_summary.append(i)\n",
    "\n",
    "stage_one = pd.DataFrame(stage_one_summary)"
   ],
   "id": "cell-15"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_one[[\"classifier\", \"tpr\", \"fpr\", \"confusion_matrix\"]].rename(\n",
    "        columns = {\n",
    "            \"classifier\"       : \"Classifier\",\n",
    "            \"tpr\"              : \"TPR\",\n",
    "            \"fpr\"              : \"FPR\",\n",
    "            \"confusion_matrix\" : \"Confussion Matrix\"\n",
    "        },\n",
    "        # inplace = True\n",
    "    ).style.hide(axis=\"index\").format({\n",
    "    \"TPR\": \"{:,.2f}\",\n",
    "    \"FPR\": \"{:,.2f}\"\n",
    "})"
   ],
   "id": "d35c6b3a-0362-427b-a91f-cef05545b719"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "35.00 % of the EU team classified articles better than Gemini (7 people)."
     ]
    }
   ],
   "source": [
    "better_than_gemini = classification_performance.loc[\n",
    "    (classification_performance['accuracy'] >= 0.8) &\n",
    "    (classification_performance['precision'] >= 0.8) &\n",
    "    (classification_performance['recall'] >= 0.54) &\n",
    "    (classification_performance['f1'] >= 0.64)\n",
    "]\n",
    "p = len(better_than_gemini) / len(classification_performance)\n",
    "print(f\"{p*100:.2f} % of the EU team classified articles better than Gemini ({len(better_than_gemini)} people).\")"
   ],
   "id": "cell-17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Two Metrics"
   ],
   "id": "cell-18"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI Metrics"
   ],
   "id": "cell-19"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_data = AI_data[AI_data['horacio_rol'] == 1]\n",
    "\n",
    "gpt_columns = [\n",
    "    'GPT_pillar_1','GPT_pillar_2','GPT_pillar_3','GPT_pillar_4',\n",
    "    'GPT_pillar_5','GPT_pillar_6','GPT_pillar_7','GPT_pillar_8'\n",
    "]\n",
    "gemini_columns = [\n",
    "    'Gemini_pillar_1','Gemini_pillar_2','Gemini_pillar_3','Gemini_pillar_4',\n",
    "    'Gemini_pillar_5','Gemini_pillar_6','Gemini_pillar_7','Gemini_pillar_8'\n",
    "]\n",
    "horacio_columns = [\n",
    "    'horacio_pillar_1', 'horacio_pillar_2', 'horacio_pillar_3', 'horacio_pillar_4', \n",
    "    'horacio_pillar_5', 'horacio_pillar_6', 'horacio_pillar_7', 'horacio_pillar_8'\n",
    "]\n",
    "\n",
    "performance_data = []\n",
    "for horacio, gpt, gemini in zip(horacio_columns, gpt_columns, gemini_columns):\n",
    "    \n",
    "    gpt_performance = calculate_performance(AI_data, gpt, horacio)\n",
    "    gpt_performance['Classifier'] = 'GPT'\n",
    "    gpt_performance['Model_Column'] = gpt\n",
    "    gpt_performance['Horacio'] = horacio\n",
    "    performance_data.append(gpt_performance)\n",
    "    \n",
    "    gemini_performance = calculate_performance(AI_data, gemini, horacio)\n",
    "    gemini_performance['Classifier'] = 'Gemini'\n",
    "    gemini_performance['Model_Column'] = gemini\n",
    "    gemini_performance['Horacio'] = horacio\n",
    "    performance_data.append(gemini_performance)\n",
    "\n",
    "AI_performance = pd.DataFrame(performance_data)"
   ],
   "id": "cell-20"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human Metrics"
   ],
   "id": "cell-21"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_two = {}\n",
    "for classifier, df in dataframes.items():\n",
    "    filtered_df = df.loc[df['horacio_ROL'] == 1]\n",
    "    stage_two[classifier] = filtered_df\n",
    "\n",
    "EU_columns = [\n",
    "    'model_pillar_1', 'model_pillar_2', 'model_pillar_3', 'model_pillar_4', \n",
    "    'model_pillar_5', 'model_pillar_6', 'model_pillar_7', 'model_pillar_8'\n",
    "]\n",
    "horacio_columns = [\n",
    "    'horacio_pillar_1', 'horacio_pillar_2', 'horacio_pillar_3', 'horacio_pillar_4',\n",
    "    'horacio_pillar_5', 'horacio_pillar_6', 'horacio_pillar_7', 'horacio_pillar_8'\n",
    "]\n",
    "\n",
    "stage_two_classification_performance = []\n",
    "\n",
    "for classifier in stage_two:\n",
    "    for i, (eu_col, horacio_col) in enumerate(zip(EU_columns, horacio_columns)):\n",
    "        classifier_df = stage_two[classifier]\n",
    "\n",
    "        metrics = calculate_performance(classifier_df, eu_col, horacio_col)\n",
    "\n",
    "        new_row = {\n",
    "            'classifier': classifier,\n",
    "            'pillar': f'Pillar {i + 1}',\n",
    "            'accuracy': metrics['accuracy'],\n",
    "            'precision': metrics['precision'],\n",
    "            'recall': metrics['recall'],\n",
    "            'f1': metrics['f1'],\n",
    "            'mcc': metrics['mcc'],\n",
    "            'tpr' : metrics['tpr'],\n",
    "            'fpr' : metrics['fpr'],\n",
    "            'confusion_matrix': [metrics['confusion_matrix']],\n",
    "            'true_pos' : metrics['true_pos'],\n",
    "            'true_neg' : metrics['true_neg'],\n",
    "            'false_pos' : metrics['false_pos'],\n",
    "            'false_neg' : metrics['false_neg']\n",
    "            }\n",
    "\n",
    "        stage_two_classification_performance.append(new_row)\n",
    "\n",
    "stage_two_classification_performance = pd.DataFrame(stage_two_classification_performance)"
   ],
   "id": "cell-22"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_pillar(column):\n",
    "    if 'pillar_' in column:\n",
    "        pillar_number = column.split('_')[-1]\n",
    "        return f'Pillar {pillar_number}'\n",
    "    \n",
    "AI_performance['pillar'] = AI_performance['Model_Column'].apply(map_pillar)"
   ],
   "id": "cell-23"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_performance = AI_performance.rename(\n",
    "    columns = {\n",
    "        'Classifier' : 'classifier', \n",
    "        'confusion matrix'  : 'confusion_matrix'\n",
    "    }\n",
    ")\n",
    "AI_performance = AI_performance.drop(columns = ['Model_Column', 'Horacio'])\n",
    "performance = pd.concat([AI_performance, stage_two_classification_performance], ignore_index=True)"
   ],
   "id": "cell-24"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/7x/fdwfv0y13yz0y3sjb4mwznqm0000gp/T/ipykernel_47536/406494460.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p1_top['confusion_matrix'] = np.array(p1_top['confusion_matrix'])\n",
      "/var/folders/7x/fdwfv0y13yz0y3sjb4mwznqm0000gp/T/ipykernel_47536/406494460.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eu_p1['confusion_matrix'] = np.array(eu_p1['confusion_matrix'])"
     ]
    }
   ],
   "source": [
    "p1 = performance.loc[performance['pillar'] == \"Pillar 1\"]\n",
    "pillar_one = []\n",
    "\n",
    "p1_top = p1.loc[\n",
    "    (p1['classifier'] != 'lcleary') & (p1['tpr'] >= 0.5) & (p1['fpr'] < .4)\n",
    "]\n",
    "p1_top['confusion_matrix'] = np.array(p1_top['confusion_matrix'])\n",
    "eu_p1 = p1.loc[\n",
    "    (p1['classifier'] != 'GPT') & (p1['classifier'] != 'Gemini')\n",
    "]\n",
    "eu_p1['confusion_matrix'] = np.array(eu_p1['confusion_matrix'])\n",
    "\n",
    "gem_p1 = {\n",
    "    'tpr' : p1.loc[(p1['classifier'] == 'Gemini')]['tpr'].iloc[0],\n",
    "    'fpr' : p1.loc[(p1['classifier'] == 'Gemini')]['fpr'].iloc[0],\n",
    "    'confusion_matrix' : np.array(p1.loc[(p1['classifier'] == 'Gemini')]['confusion_matrix'].iloc[0]),\n",
    "    'classifier' : 'Gemini',\n",
    "    'pillar' : 'Pillar 1'\n",
    "}\n",
    "\n",
    "gpt_p1 = {\n",
    "    'tpr': p1.loc[p1['classifier'] == 'GPT', 'tpr'].iloc[0],\n",
    "    'fpr': p1.loc[p1['classifier'] == 'GPT', 'fpr'].iloc[0],  \n",
    "    'confusion_matrix': np.array(p1.loc[p1['classifier'] == 'GPT', 'confusion_matrix'].iloc[0]),\n",
    "    'classifier': 'GPT',\n",
    "    'pillar': 'Pillar 1'\n",
    "}\n",
    "\n",
    "top_p1 = {\n",
    "    'tpr': p1_top['tpr'].mean(),\n",
    "    'fpr': p1_top['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[p1_top['true_neg'].sum(), p1_top['false_pos'].sum()],\n",
    "                        [p1_top['false_neg'].sum(), p1_top['true_pos'].sum()]]),\n",
    "    'classifier': 'Top Human Classifiers',\n",
    "    'pillar': 'Pillar 1'\n",
    "}\n",
    "\n",
    "all_eu_p1 = {\n",
    "    'tpr' : eu_p1['tpr'].mean(),\n",
    "    'fpr' : eu_p1['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[eu_p1['true_neg'].sum(),eu_p1['false_pos'].sum()],\n",
    "                        [eu_p1['false_neg'].sum(), eu_p1['true_pos'].sum()]]),\n",
    "    'classifier' : 'Human Classifiers',\n",
    "    'pillar' : 'Pillar 1'\n",
    "}\n",
    "\n",
    "for i in [gpt_p1, gem_p1, top_p1, all_eu_p1]:\n",
    "    pillar_one.append(i)\n",
    "\n",
    "pillar_one = pd.DataFrame(pillar_one)"
   ],
   "id": "cell-25"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/7x/fdwfv0y13yz0y3sjb4mwznqm0000gp/T/ipykernel_47536/1115769891.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eu_p2['confusion_matrix'] = np.array(eu_p2['confusion_matrix'])"
     ]
    }
   ],
   "source": [
    "p2 = performance.loc[performance['pillar'] == \"Pillar 2\"]\n",
    "\n",
    "pillar_two = []\n",
    "\n",
    "p2_top = p2.loc[\n",
    "    (p2['classifier'] != 'lcleary') & (p2['tpr'] >= 0.5) & (p2['fpr'] < .4)\n",
    "]\n",
    "eu_p2 = p2.loc[\n",
    "    (p2['classifier'] != 'GPT') & (p2['classifier'] != 'Gemini')\n",
    "]\n",
    "eu_p2['confusion_matrix'] = np.array(eu_p2['confusion_matrix'])\n",
    "\n",
    "gem_p2 = {\n",
    "    'tpr' : p2.loc[(p2['classifier'] == 'Gemini')]['tpr'].iloc[0],\n",
    "    'fpr' : p2.loc[(p2['classifier'] == 'Gemini')]['fpr'].iloc[0],\n",
    "    'confusion_matrix' : np.array(p2.loc[(p2['classifier'] == 'Gemini')]['confusion_matrix'].iloc[0]),\n",
    "    'classifier' : 'Gemini',\n",
    "    'pillar' : 'Pillar 2'\n",
    "}\n",
    "\n",
    "gpt_p2 = {\n",
    "    'tpr': p2.loc[p2['classifier'] == 'GPT', 'tpr'].iloc[0],\n",
    "    'fpr': p2.loc[p2['classifier'] == 'GPT', 'fpr'].iloc[0],  \n",
    "    'confusion_matrix': np.array(p2.loc[p2['classifier'] == 'GPT', 'confusion_matrix'].iloc[0]),\n",
    "    'classifier': 'GPT',\n",
    "    'pillar': 'Pillar 2'\n",
    "}\n",
    "\n",
    "top_p2 = {\n",
    "    'tpr': p2_top['tpr'].mean(),\n",
    "    'fpr': p2_top['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[p2_top['true_neg'].sum(), p2_top['false_pos'].sum()],\n",
    "                        [p2_top['false_neg'].sum(), p2_top['true_pos'].sum()]]),\n",
    "    'classifier': 'Top Human Classifiers',\n",
    "    'pillar': 'Pillar 2'\n",
    "}\n",
    "\n",
    "all_eu_p2 = {\n",
    "    'tpr' : eu_p2['tpr'].mean(),\n",
    "    'fpr' : eu_p2['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[eu_p2['true_neg'].sum(),eu_p2['false_pos'].sum()],\n",
    "                        [eu_p2['false_neg'].sum(), eu_p2['true_pos'].sum()]]),\n",
    "    'classifier' : 'Human Classifiers',\n",
    "    'pillar' : 'Pillar 2'\n",
    "}\n",
    "\n",
    "for i in [gpt_p2, gem_p2, top_p2, all_eu_p2]:\n",
    "    pillar_two.append(i)\n",
    "\n",
    "pillar_two = pd.DataFrame(pillar_two)"
   ],
   "id": "cell-26"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/7x/fdwfv0y13yz0y3sjb4mwznqm0000gp/T/ipykernel_47536/4165617852.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eu_p3['confusion_matrix'] = np.array(eu_p3['confusion_matrix'])"
     ]
    }
   ],
   "source": [
    "p3  = performance.loc[performance['pillar'] == \"Pillar 3\"]\n",
    "\n",
    "pillar_three = []\n",
    "\n",
    "p3_top = p3.loc[\n",
    "    (p3['classifier'] != 'lcleary') & (p3['tpr'] >= 0.5) & (p3['fpr'] < .4)\n",
    "]\n",
    "eu_p3 = p3.loc[\n",
    "    (p3['classifier'] != 'GPT') & (p3['classifier'] != 'Gemini')\n",
    "]\n",
    "eu_p3['confusion_matrix'] = np.array(eu_p3['confusion_matrix'])\n",
    "\n",
    "gem_p3 = {\n",
    "    'tpr' : p3.loc[(p3['classifier'] == 'Gemini')]['tpr'].iloc[0],\n",
    "    'fpr' : p3.loc[(p3['classifier'] == 'Gemini')]['fpr'].iloc[0],\n",
    "    'confusion_matrix' : np.array(p3.loc[(p3['classifier'] == 'Gemini')]['confusion_matrix'].iloc[0]),\n",
    "    'classifier' : 'Gemini',\n",
    "    'pillar' : 'Pillar 3'\n",
    "}\n",
    "\n",
    "gpt_p3 = {\n",
    "    'tpr': p3.loc[p3['classifier'] == 'GPT', 'tpr'].iloc[0],\n",
    "    'fpr': p3.loc[p3['classifier'] == 'GPT', 'fpr'].iloc[0],  \n",
    "    'confusion_matrix': np.array(p3.loc[p3['classifier'] == 'GPT', 'confusion_matrix'].iloc[0]),\n",
    "    'classifier': 'GPT',\n",
    "    'pillar': 'Pillar 3'\n",
    "}\n",
    "\n",
    "top_p3 = {\n",
    "    'tpr': p3_top['tpr'].mean(),\n",
    "    'fpr': p3_top['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[p3_top['true_neg'].sum(), p3_top['false_pos'].sum()],\n",
    "                        [p3_top['false_neg'].sum(), p3_top['true_pos'].sum()]]),\n",
    "    'classifier': 'Top Human Classifiers',\n",
    "    'pillar': 'Pillar 3'\n",
    "}\n",
    "\n",
    "\n",
    "all_eu_p3 = {\n",
    "    'tpr' : eu_p3['tpr'].mean(),\n",
    "    'fpr' : eu_p3['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[eu_p3['true_neg'].sum(),eu_p3['false_pos'].sum()],\n",
    "                        [eu_p3['false_neg'].sum(), eu_p3['true_pos'].sum()]]),\n",
    "    'classifier' : 'Human Classifiers',\n",
    "    'pillar' : 'Pillar 3'\n",
    "}\n",
    "\n",
    "for i in [gpt_p3, gem_p3, top_p3, all_eu_p3]:\n",
    "    pillar_three.append(i)\n",
    "\n",
    "pillar_three = pd.DataFrame(pillar_two)"
   ],
   "id": "cell-27"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/7x/fdwfv0y13yz0y3sjb4mwznqm0000gp/T/ipykernel_47536/2076089035.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eu_p4['confusion_matrix'] = np.array(eu_p4['confusion_matrix'])"
     ]
    }
   ],
   "source": [
    "p4 = performance.loc[performance['pillar'] == \"Pillar 4\"]\n",
    "\n",
    "pillar_four = []\n",
    "\n",
    "p4_top = p4.loc[\n",
    "    (p4['classifier'] != 'lcleary') & (p4['tpr'] >= 0.5) & (p4['fpr'] < .4)\n",
    "]\n",
    "eu_p4 = p4.loc[\n",
    "    (p4['classifier'] != 'GPT') & (p4['classifier'] != 'Gemini')\n",
    "]\n",
    "eu_p4['confusion_matrix'] = np.array(eu_p4['confusion_matrix'])\n",
    "\n",
    "gem_p4 = {\n",
    "    'tpr' : p4.loc[(p4['classifier'] == 'Gemini')]['tpr'].iloc[0],\n",
    "    'fpr' : p4.loc[(p4['classifier'] == 'Gemini')]['fpr'].iloc[0],\n",
    "    'confusion_matrix' : np.array(p4.loc[(p4['classifier'] == 'Gemini')]['confusion_matrix'].iloc[0]),\n",
    "    'classifier' : 'Gemini',\n",
    "    'pillar' : 'Pillar 4'\n",
    "}\n",
    "\n",
    "gpt_p4 = {\n",
    "    'tpr': p4.loc[p4['classifier'] == 'GPT', 'tpr'].iloc[0],\n",
    "    'fpr': p4.loc[p4['classifier'] == 'GPT', 'fpr'].iloc[0],  \n",
    "    'confusion_matrix': np.array(p4.loc[p4['classifier'] == 'GPT', 'confusion_matrix'].iloc[0]),\n",
    "    'classifier': 'GPT',\n",
    "    'pillar': 'Pillar 4'\n",
    "}\n",
    "\n",
    "top_p4 = {\n",
    "    'tpr': p4_top['tpr'].mean(),\n",
    "    'fpr': p4_top['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[p4_top['true_neg'].sum(), p4_top['false_pos'].sum()],\n",
    "                        [p4_top['false_neg'].sum(), p4_top['true_pos'].sum()]]),\n",
    "    'classifier': 'Top Human Classifiers',\n",
    "    'pillar': 'Pillar 4'\n",
    "}\n",
    "\n",
    "\n",
    "all_eu_p4 = {\n",
    "    'tpr' : eu_p4['tpr'].mean(),\n",
    "    'fpr' : eu_p4['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[eu_p4['true_neg'].sum(),eu_p4['false_pos'].sum()],\n",
    "                        [eu_p4['false_neg'].sum(), eu_p4['true_pos'].sum()]]),\n",
    "    'classifier' : 'Human Classifiers',\n",
    "    'pillar' : 'Pillar 4'\n",
    "}\n",
    "\n",
    "for i in [gpt_p4, gem_p4, top_p4, all_eu_p4]:\n",
    "    pillar_four.append(i)\n",
    "\n",
    "pillar_four = pd.DataFrame(pillar_four)"
   ],
   "id": "cell-28"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/7x/fdwfv0y13yz0y3sjb4mwznqm0000gp/T/ipykernel_47536/775791368.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eu_p5['confusion_matrix'] = np.array(eu_p5['confusion_matrix'])"
     ]
    }
   ],
   "source": [
    "p5 = performance.loc[performance['pillar'] == \"Pillar 5\"]\n",
    "\n",
    "pillar_five = []\n",
    "\n",
    "p5_top = p5.loc[\n",
    "    (p5['classifier'] != 'lcleary') & (p5['tpr'] >= 0.5) & (p5['fpr'] < .4)\n",
    "]\n",
    "eu_p5 = p5.loc[\n",
    "    (p5['classifier'] != 'GPT') & (p5['classifier'] != 'Gemini')\n",
    "]\n",
    "eu_p5['confusion_matrix'] = np.array(eu_p5['confusion_matrix'])\n",
    "\n",
    "gem_p5 = {\n",
    "    'tpr' : p5.loc[(p5['classifier'] == 'Gemini')]['tpr'].iloc[0],\n",
    "    'fpr' : p5.loc[(p5['classifier'] == 'Gemini')]['fpr'].iloc[0],\n",
    "    'confusion_matrix' : np.array(p5.loc[(p5['classifier'] == 'Gemini')]['confusion_matrix'].iloc[0]),\n",
    "    'classifier' : 'Gemini',\n",
    "    'pillar' : 'Pillar 5'\n",
    "}\n",
    "\n",
    "gpt_p5 = {\n",
    "    'tpr': p5.loc[p5['classifier'] == 'GPT', 'tpr'].iloc[0],\n",
    "    'fpr': p5.loc[p5['classifier'] == 'GPT', 'fpr'].iloc[0],  \n",
    "    'confusion_matrix': np.array(p5.loc[p5['classifier'] == 'GPT', 'confusion_matrix'].iloc[0]),\n",
    "    'classifier': 'GPT',\n",
    "    'pillar': 'Pillar 5'\n",
    "}\n",
    "\n",
    "top_p5 = {\n",
    "    'tpr': p5_top['tpr'].mean(),\n",
    "    'fpr': p5_top['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[p5_top['true_neg'].sum(), p5_top['false_pos'].sum()],\n",
    "                        [p5_top['false_neg'].sum(), p5_top['true_pos'].sum()]]),\n",
    "    'classifier': 'Top Human Classifiers',\n",
    "    'pillar': 'Pillar 5'\n",
    "}\n",
    "\n",
    "all_eu_p5 = {\n",
    "    'tpr' : eu_p5['tpr'].mean(),\n",
    "    'fpr' : eu_p5['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[eu_p5['true_neg'].sum(),eu_p5['false_pos'].sum()],\n",
    "                        [eu_p5['false_neg'].sum(), eu_p5['true_pos'].sum()]]),\n",
    "    'classifier' : 'Human Classifiers',\n",
    "    'pillar' : 'Pillar 5'\n",
    "}\n",
    "\n",
    "for i in [gpt_p5, gem_p5, top_p5, all_eu_p5]:\n",
    "    pillar_five.append(i)\n",
    "\n",
    "pillar_five = pd.DataFrame(pillar_five)"
   ],
   "id": "cell-29"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/7x/fdwfv0y13yz0y3sjb4mwznqm0000gp/T/ipykernel_47536/4058969709.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eu_p6['confusion_matrix'] = np.array(eu_p6['confusion_matrix'])"
     ]
    }
   ],
   "source": [
    "p6 = performance.loc[performance['pillar'] == \"Pillar 6\"]\n",
    "\n",
    "pillar_six = []\n",
    "\n",
    "p6_top = p6.loc[\n",
    "    (p6['classifier'] != 'lcleary') & (p6['tpr'] >= 0.5) & (p6['fpr'] < .4)\n",
    "]\n",
    "eu_p6 = p6.loc[\n",
    "    (p6['classifier'] != 'GPT') & (p6['classifier'] != 'Gemini')\n",
    "]\n",
    "eu_p6['confusion_matrix'] = np.array(eu_p6['confusion_matrix'])\n",
    "\n",
    "gem_p6 = {\n",
    "    'tpr' : p6.loc[(p6['classifier'] == 'Gemini')]['tpr'].iloc[0],\n",
    "    'fpr' : p6.loc[(p6['classifier'] == 'Gemini')]['fpr'].iloc[0],\n",
    "    'confusion_matrix' : np.array(p6.loc[(p6['classifier'] == 'Gemini')]['confusion_matrix'].iloc[0]),\n",
    "    'classifier' : 'Gemini',\n",
    "    'pillar' : 'Pillar 6'\n",
    "}\n",
    "\n",
    "gpt_p6 = {\n",
    "    'tpr': p6.loc[p6['classifier'] == 'GPT', 'tpr'].iloc[0],\n",
    "    'fpr': p6.loc[p6['classifier'] == 'GPT', 'fpr'].iloc[0],  \n",
    "    'confusion_matrix': np.array(p6.loc[p6['classifier'] == 'GPT', 'confusion_matrix'].iloc[0]),\n",
    "    'classifier': 'GPT',\n",
    "    'pillar': 'Pillar 6'\n",
    "}\n",
    "\n",
    "top_p6 = {\n",
    "    'tpr': p6_top['tpr'].mean(),\n",
    "    'fpr': p6_top['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[p6_top['true_neg'].sum(), p6_top['false_pos'].sum()],\n",
    "                        [p6_top['false_neg'].sum(), p6_top['true_pos'].sum()]]),\n",
    "    'classifier': 'Top Human Classifiers',\n",
    "    'pillar': 'Pillar 6'\n",
    "}\n",
    "\n",
    "all_eu_p6 = {\n",
    "    'tpr' : eu_p6['tpr'].mean(),\n",
    "    'fpr' : eu_p6['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[eu_p6['true_neg'].sum(),eu_p6['false_pos'].sum()],\n",
    "                        [eu_p6['false_neg'].sum(), eu_p6['true_pos'].sum()]]),\n",
    "    'classifier' : 'Human Classifiers',\n",
    "    'pillar' : 'Pillar 6'\n",
    "}\n",
    "\n",
    "for i in [gpt_p6, gem_p6, top_p6, all_eu_p6]:\n",
    "    pillar_six.append(i)\n",
    "\n",
    "pillar_six = pd.DataFrame(pillar_six)"
   ],
   "id": "cell-30"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/7x/fdwfv0y13yz0y3sjb4mwznqm0000gp/T/ipykernel_47536/3508723912.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eu_p7['confusion_matrix'] = np.array(eu_p7['confusion_matrix'])"
     ]
    }
   ],
   "source": [
    "p7 = performance.loc[performance['pillar'] == \"Pillar 7\"]\n",
    "\n",
    "pillar_seven = []\n",
    "\n",
    "p7_top = p7.loc[\n",
    "    (p7['classifier'] != 'lcleary') & (p7['tpr'] >= 0.5) & (p7['fpr'] < .4)\n",
    "]\n",
    "eu_p7 = p7.loc[\n",
    "    (p7['classifier'] != 'GPT') & (p7['classifier'] != 'Gemini')\n",
    "]\n",
    "eu_p7['confusion_matrix'] = np.array(eu_p7['confusion_matrix'])\n",
    "\n",
    "gem_p7 = {\n",
    "    'tpr' : p7.loc[(p7['classifier'] == 'Gemini')]['tpr'].iloc[0],\n",
    "    'fpr' : p7.loc[(p7['classifier'] == 'Gemini')]['fpr'].iloc[0],\n",
    "    'confusion_matrix' : np.array(p7.loc[(p7['classifier'] == 'Gemini')]['confusion_matrix'].iloc[0]),\n",
    "    'classifier' : 'Gemini',\n",
    "    'pillar' : 'Pillar 7'\n",
    "}\n",
    "\n",
    "gpt_p7= {\n",
    "    'tpr': p7.loc[p7['classifier'] == 'GPT', 'tpr'].iloc[0],\n",
    "    'fpr': p7.loc[p7['classifier'] == 'GPT', 'fpr'].iloc[0],  \n",
    "    'confusion_matrix': np.array(p7.loc[p7['classifier'] == 'GPT', 'confusion_matrix'].iloc[0]),\n",
    "    'classifier': 'GPT',\n",
    "    'pillar': 'Pillar 7'\n",
    "}\n",
    "\n",
    "top_p7 = {\n",
    "    'tpr': p7_top['tpr'].mean(),\n",
    "    'fpr': p7_top['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[p7_top['true_neg'].sum(), p7_top['false_pos'].sum()],\n",
    "                        [p7_top['false_neg'].sum(), p7_top['true_pos'].sum()]]),\n",
    "    'classifier': 'Top Human Classifiers',\n",
    "    'pillar': 'Pillar 7'\n",
    "}\n",
    "\n",
    "all_eu_p7 = {\n",
    "    'tpr' : eu_p7['tpr'].mean(),\n",
    "    'fpr' : eu_p7['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[eu_p7['true_neg'].sum(),eu_p7['false_pos'].sum()],\n",
    "                        [eu_p7['false_neg'].sum(), eu_p7['true_pos'].sum()]]),\n",
    "    'classifier' : 'Human Classifiers',\n",
    "    'pillar' : 'Pillar 7'\n",
    "}\n",
    "\n",
    "for i in [gpt_p7, gem_p7, top_p7, all_eu_p7]:\n",
    "    pillar_seven.append(i)\n",
    "\n",
    "pillar_seven = pd.DataFrame(pillar_seven)"
   ],
   "id": "cell-31"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/7x/fdwfv0y13yz0y3sjb4mwznqm0000gp/T/ipykernel_47536/1783717482.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eu_p8['confusion_matrix'] = np.array(eu_p8['confusion_matrix'])"
     ]
    }
   ],
   "source": [
    "p8 = performance.loc[performance['pillar'] == \"Pillar 8\"]\n",
    "\n",
    "pillar_eight = []\n",
    "\n",
    "p8_top = p8.loc[\n",
    "    (p8['classifier'] != 'lcleary') & (p8['tpr'] >= 0.5) & (p8['fpr'] < .4)\n",
    "]\n",
    "eu_p8 = p8.loc[\n",
    "    (p8['classifier'] != 'GPT') & (p8['classifier'] != 'Gemini')\n",
    "]\n",
    "eu_p8['confusion_matrix'] = np.array(eu_p8['confusion_matrix'])\n",
    "\n",
    "gem_p8 = {\n",
    "    'tpr' : p8.loc[(p8['classifier'] == 'Gemini')]['tpr'].iloc[0],\n",
    "    'fpr' : p8.loc[(p8['classifier'] == 'Gemini')]['fpr'].iloc[0],\n",
    "    'confusion_matrix' : np.array(p8.loc[(p8['classifier'] == 'Gemini')]['confusion_matrix'].iloc[0]),\n",
    "    'classifier' : 'Gemini',\n",
    "    'pillar' : 'Pillar 8'\n",
    "}\n",
    "\n",
    "gpt_p8 = {\n",
    "    'tpr': p8.loc[p8['classifier'] == 'GPT', 'tpr'].iloc[0],\n",
    "    'fpr': p8.loc[p8['classifier'] == 'GPT', 'fpr'].iloc[0],  \n",
    "    'confusion_matrix': np.array(p8.loc[p8['classifier'] == 'GPT', 'confusion_matrix'].iloc[0]),\n",
    "    'classifier': 'GPT',\n",
    "    'pillar': 'Pillar 8'\n",
    "}\n",
    "\n",
    "top_p8 = {\n",
    "    'tpr': p8_top['tpr'].mean(),\n",
    "    'fpr': p8_top['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[p8_top['true_neg'].sum(), p8_top['false_pos'].sum()],\n",
    "                        [p8_top['false_neg'].sum(), p8_top['true_pos'].sum()]]),\n",
    "    'classifier': 'Top Human Classifiers',\n",
    "    'pillar': 'Pillar 8'\n",
    "}\n",
    "\n",
    "\n",
    "all_eu_p8 = {\n",
    "    'tpr' : eu_p8['tpr'].mean(),\n",
    "    'fpr' : eu_p8['fpr'].mean(),\n",
    "    'confusion_matrix' : np.array([[eu_p8['true_neg'].sum(),eu_p8['false_pos'].sum()],\n",
    "                        [eu_p8['false_neg'].sum(), eu_p8['true_pos'].sum()]]),\n",
    "    'classifier' : 'Human Classifiers',\n",
    "    'pillar' : 'Pillar 8'\n",
    "}\n",
    "\n",
    "for i in [gpt_p8, gem_p8, top_p8, all_eu_p8]:\n",
    "    pillar_eight.append(i)\n",
    "\n",
    "pillar_eight = pd.DataFrame(pillar_eight)"
   ],
   "id": "cell-32"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [pillar_one, pillar_four, pillar_five]\n",
    "stage_two = pd.concat(dataframes)\n",
    "stage_two[[\"classifier\", \"pillar\", \"tpr\", \"fpr\", \"confusion_matrix\"]].rename(\n",
    "        columns = {\n",
    "            \"classifier\"       : \"Classifier\",\n",
    "            \"pillar\"           : \"Pillar\",\n",
    "            \"tpr\"              : \"TPR\",\n",
    "            \"fpr\"              : \"FPR\",\n",
    "            \"confusion_matrix\" : \"Confussion Matrix\"\n",
    "        },\n",
    "        # inplace = True\n",
    "    ).style.hide(axis=\"index\").format({\n",
    "    \"TPR\": \"{:,.2f}\",\n",
    "    \"FPR\": \"{:,.2f}\"\n",
    "})"
   ],
   "id": "8bdf8759-7aac-4722-9056-9684f8a035fd"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
